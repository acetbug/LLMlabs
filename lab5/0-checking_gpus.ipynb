{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["## Lab 5.0 Using GPUs"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The following torch commands allow you to check GPU status. "]}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [], "source": ["# ensure that you have a GPU available\n", "import torch\n", "\n", "torch.cuda.is_available() "]}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [], "source": ["torch.cuda.device_count()"]}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [], "source": ["torch.cuda.current_device() #returns you the ID of your current device\n"]}, {"cell_type": "code", "execution_count": 20, "metadata": {}, "outputs": [], "source": ["# if you have multiple GPUs, you can set the device to a specific GPU\n", "\n", "torch.cuda.set_device(0) #where 1 is the ID of device \n"]}, {"cell_type": "code", "execution_count": 21, "metadata": {}, "outputs": [], "source": ["torch.cuda.current_device() #returns you the ID of your current device\n"]}, {"cell_type": "code", "execution_count": 28, "metadata": {}, "outputs": [], "source": ["# show all gpu properties\n", "for i in range(torch.cuda.device_count()):\n", "    print(torch.cuda.get_device_properties(i)) #returns you the properties of the device\n", "\n", "# show the name of the device\n", "for i in range(torch.cuda.device_count()):\n", "    print(torch.cuda.get_device_name(i)) #returns you the name of the device"]}, {"cell_type": "code", "execution_count": 29, "metadata": {}, "outputs": [], "source": ["for i in range(torch.cuda.device_count()):\n", "    print(torch.cuda.memory_allocated(i)) #returns you the current GPU memory usage by tensors in bytes for a given device\n"]}, {"cell_type": "code", "execution_count": 30, "metadata": {}, "outputs": [], "source": ["for i in range(torch.cuda.device_count()):\n", "    print(torch.cuda.memory_reserved(i)) #returns you the current GPU memory managed by caching allocator in bytes for a given device, in previous PyTorch versions the command was torch.cuda.memory_cached\n"]}, {"cell_type": "code", "execution_count": 31, "metadata": {}, "outputs": [], "source": ["# clear the cache\n", "\n", "torch.cuda.empty_cache() \n"]}, {"cell_type": "code", "execution_count": 32, "metadata": {}, "outputs": [], "source": ["## Specifying a device to use\n", "## the following are equivalent\n", "\n", "cuda1 = torch.device(\"cuda:0\") #where 1 is the ID of specific device\n", "tensor = torch.tensor([0.,0.], device = cuda1)\n", "tensor = torch.tensor([0.,0.]).to(cuda1)\n", "tensor = torch.tensor([0.,0.]).cuda(cuda1)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.12"}}, "nbformat": 4, "nbformat_minor": 2}